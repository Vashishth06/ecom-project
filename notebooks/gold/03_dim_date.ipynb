{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39669ce5-6ef8-40b6-b3d0-b56e0a7e98b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "from config.table_config import PROJECT_PATH\n",
    "\n",
    "if PROJECT_PATH not in sys.path:\n",
    "    sys.path.append(PROJECT_PATH)\n",
    "\n",
    "from config import *\n",
    "from utils import *\n",
    "from pyspark.sql.functions import col, year, month, dayofmonth, dayofweek, \\\n",
    "    quarter, weekofyear, date_format, expr\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "configure_spark(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "612bd5a7-03c4-4658-b10f-08fff9c32227",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def date_dimension_transform(source_dfs):\n",
    "    \"\"\"\n",
    "    Generate date dimension (2020-2027).\n",
    "    \n",
    "    Date dimension doesn't read from silver - generates dates.\n",
    "    source_dfs is empty but required by signature.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate date range\n",
    "    start_date = datetime(2020, 1, 1)\n",
    "    end_date = datetime(2027, 12, 31)\n",
    "    \n",
    "    dates = []\n",
    "    current = start_date\n",
    "    while current <= end_date:\n",
    "        dates.append((current,))\n",
    "        current += timedelta(days=1)\n",
    "    \n",
    "    # Create DataFrame\n",
    "    date_df = spark.createDataFrame(dates, [\"date\"])\n",
    "    \n",
    "    # Add dimension attributes\n",
    "    dim_date = date_df.select(\n",
    "        # Key\n",
    "        col(\"date\").cast(\"date\").alias(\"date_key\"),\n",
    "        col(\"date\"),\n",
    "        \n",
    "        # Date parts\n",
    "        year(col(\"date\")).alias(\"year\"),\n",
    "        quarter(col(\"date\")).alias(\"quarter\"),\n",
    "        month(col(\"date\")).alias(\"month\"),\n",
    "        dayofmonth(col(\"date\")).alias(\"day\"),\n",
    "        dayofweek(col(\"date\")).alias(\"day_of_week\"),\n",
    "        weekofyear(col(\"date\")).alias(\"week_of_year\"),\n",
    "        \n",
    "        # Names\n",
    "        date_format(col(\"date\"), \"MMMM\").alias(\"month_name\"),\n",
    "        date_format(col(\"date\"), \"EEEE\").alias(\"day_name\"),\n",
    "        \n",
    "        # Flags\n",
    "        (dayofweek(col(\"date\")).isin([1, 7])).cast(\"boolean\").alias(\"is_weekend\"),\n",
    "        (month(col(\"date\")).isin([12, 1, 2])).cast(\"boolean\").alias(\"is_winter\"),\n",
    "        (month(col(\"date\")).isin([3, 4, 5])).cast(\"boolean\").alias(\"is_spring\"),\n",
    "        (month(col(\"date\")).isin([6, 7, 8])).cast(\"boolean\").alias(\"is_summer\"),\n",
    "        (month(col(\"date\")).isin([9, 10, 11])).cast(\"boolean\").alias(\"is_fall\"),\n",
    "        \n",
    "        # Fiscal year (July 1 start)\n",
    "        expr(\"CASE WHEN month >= 7 THEN year + 1 ELSE year END\").alias(\"fiscal_year\")\n",
    "    )\n",
    "    \n",
    "    return dim_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ecdf16fe-e6b0-4f2e-960f-6cd5d9097479",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "GoldTransformation(\n",
    "    spark=spark,\n",
    "    table_display_name=\"dim_date\",\n",
    "    table_type=\"dimension\",\n",
    "    source_tables=[],  # No source tables - generates data\n",
    "    target_table=f\"{CATALOG_NAME}.gold.dim_date\"\n",
    ").run(\n",
    "    catalog_name=CATALOG_NAME,\n",
    "    gold_schema=\"gold\",\n",
    "    gold_container=GOLD_BASE,\n",
    "    transform_logic=date_dimension_transform,\n",
    "    clustering_cols=[\"year\", \"month\"],\n",
    "    scd_type=1,\n",
    "    write_mode=\"overwrite\",\n",
    "    add_metadata=False  # Date dimension doesn't need created_at/updated_at\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_dim_date",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
